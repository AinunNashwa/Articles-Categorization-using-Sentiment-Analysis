# -*- coding: utf-8 -*-
"""modules_for_cat_articles.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SHZQLyVCQ_yV-91ehCCIwAH0zVOCFdj6
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import Input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Bidirectional,Embedding
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import LSTM,Dense,Dropout


class ModelCreation():
    def __init__(self):
        pass
    
    def sequential_layer(self,num_node=128,drop_rate=0.2,output_node=5):      

      max_len = 341

      vocab_size = 10000
      oov_token = 'OOV'
      tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_token)

      embedding_dim = 160
      model = Sequential()
      model.add(Input(shape=(max_len))) 
      model.add(Embedding(vocab_size,embedding_dim))
      model.add(Bidirectional(LSTM(num_node,return_sequences=(True))))
      model.add(Dropout(drop_rate))
      model.add(Bidirectional(LSTM(num_node)))
      model.add(Dropout(drop_rate))
      model.add(Dense(num_node,activation='relu'))
      model.add(Dropout(drop_rate))
      model.add(Dense(output_node,activation='softmax'))
      model.summary()

      return model

class model_evaluation():
    def __init__(self):
        pass

    def plot_graph(self,hist):

      plt.figure()
      plt.plot(hist.history['loss'])
      plt.plot(hist.history['val_loss'])
      plt.title('Loss')
      plt.legend(['training loss','validation loss'])
      plt.show()

      plt.figure()
      plt.plot(hist.history['acc'])
      plt.plot(hist.history['val_acc'])
      plt.legend(['training accuracy','validation accuracy'])
      plt.title('Accuracy')
      plt.show()